import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sqlalchemy import create_engine
import geohash2
from shapely.geometry import Point, shape
from shapely.prepared import prep
import requests
import plotly.express as px
from streamlit_lottie import st_lottie
import json

# ==================== é¡µé¢é…ç½® ====================
st.set_page_config(
    page_title="ğŸš€ ç”µå•†ç”¨æˆ·è¡Œä¸ºå®æ—¶çœ‹æ¿",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# éšè—é¡¶éƒ¨å¯¼èˆªæ 
st.markdown("""
<style>
header {
    background-color: #0a0b14 !important;
    border-bottom: none !important;
}
header .css-18e3th9 {
    display: none !important;
}
</style>
""", unsafe_allow_html=True)

# ==================== å®‰å…¨åŠ è½½ Lottie åŠ¨ç”» ====================
@st.cache_data
def load_lottie_url(url: str):
    try:
        r = requests.get(url, timeout=10)
        if r.status_code == 200 and 'application/json' in r.headers.get('content-type', ''):
            return r.json()
    except Exception as e:
        pass
    return None

# ä½¿ç”¨ GitHub æ‰˜ç®¡çš„å¯é  Lottieï¼ˆå›½å†…å¯è®¿é—®ï¼‰
LOTTIE_LOADING_URL = "https://raw.githubusercontent.com/taivu1998/public-assets/main/lotties/data-loading.json"
LOTTIE_GLOBE_URL = "https://raw.githubusercontent.com/taivu1998/public-assets/main/lotties/globe-spin.json"

lottie_loading = load_lottie_url(LOTTIE_LOADING_URL)
lottie_globe = load_lottie_url(LOTTIE_GLOBE_URL)

# ==================== å…¨å±€ CSSï¼ˆæ·±ç©ºç§‘æŠ€é£ + åŠ¨ç”»ï¼‰====================
st.markdown("""
<style>
/* ä¸»ä½“èƒŒæ™¯ */
body {
    background: #0c0e1a;
    overflow-x: hidden;
}
.stApp {
    background: transparent;
}

/* æ˜Ÿç©ºèƒŒæ™¯ */
.stApp::before {
    content: "";
    position: fixed;
    top: 0; left: 0; right: 0; bottom: 0;
    background: 
        radial-gradient(circle at 20% 30%, rgba(96, 165, 250, 0.05) 0%, transparent 40%),
        radial-gradient(circle at 80% 70%, rgba(147, 197, 253, 0.05) 0%, transparent 40%);
    z-index: -2;
    pointer-events: none;
}

/* æ ‡é¢˜å‘¼å¸åŠ¨ç”» */
@keyframes titleGlow {
    0%, 100% { text-shadow: 0 0 10px rgba(96, 165, 250, 0.7), 0 0 20px rgba(56, 189, 248, 0.5); }
    50% { text-shadow: 0 0 15px rgba(96, 165, 250, 0.9), 0 0 30px rgba(56, 189, 248, 0.7); }
}
h1 {
    background: linear-gradient(90deg, #60a5fa, #38bdf8, #a78bfa);
    -webkit-background-clip: text;
    background-clip: text;
    color: transparent;
    font-weight: 800;
    text-align: center;
    margin-bottom: 1.5rem;
    animation: titleGlow 3s ease-in-out infinite;
    font-size: 2.8rem;
}

/* æŒ‡æ ‡å¡ç‰‡ */
.metric-card {
    background: rgba(15, 23, 42, 0.6);
    backdrop-filter: blur(12px);
    border-radius: 20px;
    padding: 1.4rem;
    text-align: center;
    transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
    box-shadow: 0 8px 20px rgba(0, 0, 0, 0.4);
    border: 1px solid rgba(96, 165, 250, 0.15);
    position: relative;
}
.metric-card:hover {
    transform: translateY(-8px);
    box-shadow: 
        0 12px 30px rgba(96, 165, 250, 0.3),
        0 0 0 2px rgba(96, 165, 250, 0.5);
    border-color: rgba(96, 165, 250, 0.4);
}
.metric-value {
    font-size: 2.4rem;
    font-weight: 800;
    background: linear-gradient(90deg, #93c5fd, #c4b5fd);
    -webkit-background-clip: text;
    background-clip: text;
    color: transparent;
}
.metric-label {
    font-size: 1.05rem;
    color: #cbd5e1;
    margin-top: 0.4rem;
    font-weight: 500;
}

/* å›¾è¡¨é¢æ¿ */
.plot-container {
    background: rgba(15, 23, 42, 0.55);
    backdrop-filter: blur(10px);
    border-radius: 18px;
    padding: 16px;
    box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
    border: 1px solid rgba(96, 165, 250, 0.1);
}

/* Plotly åœ°å›¾èƒŒæ™¯ï¼ˆå…³é”®ä¿®å¤ï¼‰*/
.plotly .plotly-cartesian {
    background: rgba(15, 23, 42, 0.8) !important;
    fill: rgba(15, 23, 42, 0.8) !important;
    stroke: rgba(40, 50, 60, 0.5) !important;
}
.plotly .plotly-scatter {
    stroke: rgba(96, 165, 250, 0.7) !important;
    fill: rgba(96, 165, 250, 0.3) !important;
}
.plotly .plotly-bar {
    fill: rgba(96, 165, 250, 0.7) !important;
}

/* Streamlit è¡¨æ ¼æ ·å¼ï¼ˆç»Ÿä¸€æš—è‰²ï¼‰*/
[data-testid="stDataFrame"] {
    background: rgba(15, 23, 42, 0.7) !important;
    border: 1px solid rgba(40, 50, 60, 0.3) !important;
    border-radius: 12px;
    overflow: hidden;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
}
[data-testid="stDataFrame"] th,
[data-testid="stDataFrame"] td {
    background: rgba(15, 23, 42, 0.7) !important;
    color: #e2e8f0 !important;
    border: 1px solid rgba(40, 50, 60, 0.2) !important;
    padding: 0.6rem;
    font-size: 0.95rem;
}
[data-testid="stDataFrame"] th {
    background: rgba(25, 30, 50, 0.8) !important;
    color: #cbd5e1 !important;
    font-weight: 500;
}

/* ä¸‹æ‹‰æ¡†æ ·å¼ï¼ˆé€‰ä¸­çŠ¶æ€ï¼‰*/
.stSelectbox > div > select {
    background: rgba(25, 30, 50, 0.8) !important;
    color: #e2e8f0 !important;
    border: 1px solid rgba(40, 50, 60, 0.3) !important;
    border-radius: 8px;
    padding: 0.5rem;
    font-size: 1rem;
    outline: none;
    transition: all 0.3s ease;
}
.stSelectbox > div > select:focus {
    border-color: rgba(96, 165, 250, 0.5) !important;
    box-shadow: 0 0 0 2px rgba(96, 165, 250, 0.2) !important;
}

/* åˆ†å‰²çº¿ */
.stDivider {
    border-color: rgba(96, 165, 250, 0.3) !important;
}

/* æ»šåŠ¨æ¡ç¾åŒ– */
::-webkit-scrollbar {
    width: 8px;
}
::-webkit-scrollbar-track {
    background: rgba(15, 23, 42, 0.3);
}
::-webkit-scrollbar-thumb {
    background: linear-gradient(to bottom, #60a5fa, #38bdf8);
    border-radius: 4px;
}
</style>
""", unsafe_allow_html=True)


# ==================== æ•°æ®åº“è¿æ¥ ====================
def get_db_engine():
    # è¯·æ ¹æ®ä½ çš„å®é™…é…ç½®ä¿®æ”¹
    return create_engine("mysql+pymysql://root:123456@192.168.43.10:3306/ecommerce_db?charset=utf8mb4")

# ==================== è·å–æ•°æ®æœ€å¤§æ—¥æœŸ ====================
@st.cache_data(ttl=300)
def get_max_date():
    engine = get_db_engine()
    result = pd.read_sql("SELECT MAX(DATE(time)) AS max_date FROM user_behavior", engine)
    max_date = result.iloc[0]['max_date']
    if pd.isna(max_date):
        raise ValueError("æ•°æ®åº“ä¸­æ— æœ‰æ•ˆæ—¶é—´æ•°æ®")
    return max_date

# ==================== åœ°ç†ç›¸å…³å‡½æ•° ====================
@st.cache_resource
def load_world_geojson():
    url = "https://raw.githubusercontent.com/johan/world.geo.json/master/countries.geo.json"
    try:
        response = requests.get(url, timeout=10)
        return response.json()
    except Exception as e:
        st.error(f"âš ï¸ æ— æ³•åŠ è½½å…¨çƒåœ°å›¾æ•°æ®: {e}")
        return {"type": "FeatureCollection", "features": []}

@st.cache_resource
def build_country_index():
    world_geo = load_world_geojson()
    country_polygons = {}
    for feature in world_geo.get("features", []):
        name = feature["properties"].get("name")
        if not name or not isinstance(name, str):
            continue
        geom = shape(feature["geometry"])
        if geom.is_valid and not geom.is_empty:
            country_polygons[name] = prep(geom)
    return country_polygons

def geohash_to_country(geohash_str, country_index):
    try:
        lat, lon = geohash2.decode(geohash_str)
        point = Point(lon, lat)
        for name, polygon in country_index.items():
            if polygon.contains(point):
                return name
    except Exception:
        pass
    return None

# ==================== è·å–æ‰€æœ‰æ•°æ® ====================
@st.cache_data(ttl=120)
def fetch_all_data(days):
    engine = get_db_engine()
    max_date = get_max_date()
    start_date = max_date - timedelta(days=days)

    total_users = pd.read_sql("SELECT COUNT(DISTINCT user_id) AS total FROM user_behavior", engine).iloc[0]['total']
    yesterday = max_date - timedelta(days=1)
    new_users = pd.read_sql(f"SELECT COUNT(DISTINCT user_id) AS total FROM user_behavior WHERE DATE(time) = '{yesterday}'", engine).iloc[0]['total']
    active_users = pd.read_sql(f"SELECT COUNT(DISTINCT user_id) AS total FROM user_behavior WHERE time >= '{start_date}'", engine).iloc[0]['total']

    channel_df = pd.read_sql("""
        SELECT 
            CASE behavior_type
                WHEN '1' THEN 'æµè§ˆ'
                WHEN '2' THEN 'æ”¶è—'
                WHEN '3' THEN 'åŠ è´­'
                WHEN '4' THEN 'ä¸‹å•'
                ELSE behavior_type
            END AS channel,
            COUNT(*) AS cnt
        FROM user_behavior
        WHERE behavior_type IN ('1','2','3','4')
        GROUP BY channel
        ORDER BY FIELD(channel, 'æµè§ˆ','æ”¶è—','åŠ è´­','ä¸‹å•')
    """, engine)

    geo_raw = pd.read_sql("""
        SELECT DISTINCT user_id, user_geohash
        FROM user_behavior
        WHERE user_geohash IS NOT NULL 
          AND user_geohash != ''
          AND user_geohash REGEXP '^[0-9b-hj-np-z]{5,12}$'
        LIMIT 20000
    """, engine)

    if not geo_raw.empty:
        country_index = build_country_index()
        geo_raw['country'] = geo_raw['user_geohash'].apply(lambda gh: geohash_to_country(gh, country_index))
        geo_agg = geo_raw.dropna(subset=['country']).groupby('country').size().reset_index(name='user_count')
        geo_agg = geo_agg.sort_values('user_count', ascending=False)
    else:
        geo_agg = pd.DataFrame(columns=['country', 'user_count'])

    hourly_df = pd.read_sql(f"""
        SELECT HOUR(time) AS hour, COUNT(*) AS cnt
        FROM user_behavior
        WHERE time >= '{start_date}'
        GROUP BY hour
        ORDER BY hour
    """, engine)

    funnel_df = pd.read_sql(f"""
        SELECT
            COUNT(DISTINCT CASE WHEN behavior_type = '1' THEN user_id END) AS view,
            COUNT(DISTINCT CASE WHEN behavior_type = '3' THEN user_id END) AS cart,
            COUNT(DISTINCT CASE WHEN behavior_type = '4' THEN user_id END) AS buy
        FROM user_behavior
        WHERE time >= '{start_date}'
    """, engine).T.reset_index()
    funnel_df.columns = ['stage', 'users']
    funnel_df['stage'] = funnel_df['stage'].map({'view': 'æµè§ˆ', 'cart': 'åŠ è´­', 'buy': 'ä¸‹å•'})

    cat_df = pd.read_sql(f"""
        SELECT item_id, COUNT(*) AS cnt
        FROM user_behavior
        WHERE behavior_type = '4' AND time >= '{start_date}'
        GROUP BY item_id
        ORDER BY cnt DESC
        LIMIT 5
    """, engine)

    repeat_users = pd.read_sql(f"""
        SELECT COUNT(DISTINCT user_id) AS total
        FROM (
            SELECT user_id
            FROM user_behavior
            WHERE behavior_type = '4' AND time >= '{start_date}'
            GROUP BY user_id
            HAVING COUNT(*) >= 2
        ) t
    """, engine).iloc[0]['total']

    log_df = pd.read_sql("""
        SELECT user_id, time, item_id
        FROM user_behavior
        WHERE behavior_type = '4'
        ORDER BY time DESC
        LIMIT 10
    """, engine)
    log_df['time'] = log_df['time'].astype(str)

    return {
        'total_users': total_users,
        'new_users': new_users,
        'active_users': active_users,
        'repeat_users': repeat_users,
        'channel_df': channel_df,
        'geo_df': geo_agg,
        'hourly_df': hourly_df,
        'funnel_df': funnel_df,
        'cat_df': cat_df,
        'log_df': log_df,
        'reference_date': max_date
    }

# ==================== ä¸»ç•Œé¢ ====================
st.title("ğŸš€ ç”µå•†ç”¨æˆ·è¡Œä¸ºå®æ—¶çœ‹æ¿")

# æ˜¾ç¤ºæ•°æ®åŸºå‡†
try:
    ref_date = get_max_date()
    st.caption(f"ğŸŒŒ æ•°æ®æ—¶é—´åŸºå‡†ï¼š{ref_date} | æ‰€æœ‰â€œè¿‘æœŸâ€ç»Ÿè®¡å‡ä»¥æ­¤ä¸ºé”šç‚¹")
except Exception as e:
    st.error(f"âŒ æ— æ³•è·å–æ•°æ®æ—¶é—´èŒƒå›´ï¼š{e}")
    st.stop()

col1, col2 = st.columns([1, 3])
with col1:
    days = st.selectbox("ğŸ“Š æ—¶é—´èŒƒå›´", [1, 3, 7, 30], index=2)

# å®‰å…¨åŠ è½½æ•°æ®
data = None
with st.spinner(""):
    if lottie_loading is not None:
        st_lottie(lottie_loading, height=100, key="loading_data")
    else:
        st.info("ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®ï¼Œè¯·ç¨å€™...")
    data = fetch_all_data(days)

if data is None:
    st.error("âŒ æ•°æ®åŠ è½½å¤±è´¥")
    st.stop()

# ==================== æŒ‡æ ‡å¡ç‰‡ ====================
cols = st.columns(4)
metrics = [
    ("ğŸ‘¥ æ€»ç”¨æˆ·æ•°", data['total_users']),
    ("ğŸ†• æ˜¨æ—¥æ–°å¢", data['new_users']),
    ("ğŸ”¥ è¿‘æœŸæ´»è·ƒ", data['active_users']),
    ("ğŸ” å¤è´­ç”¨æˆ·", data['repeat_users'])
]
for col, (label, value) in zip(cols, metrics):
    with col:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{value:,}</div>
            <div class="metric-label">{label}</div>
        </div>
        """, unsafe_allow_html=True)

st.divider()

# ==================== å·¦å³å¸ƒå±€ ====================
left_col, right_col = st.columns([2, 3])

with left_col:
    st.subheader("ğŸ“ˆ è¡Œä¸ºæ¸ é“åˆ†å¸ƒ")
    fig1 = px.pie(data['channel_df'], values='cnt', names='channel', hole=0.4,
                  color_discrete_sequence=px.colors.qualitative.Pastel1)
    fig1.update_layout(margin=dict(t=30, b=0, l=0, r=0), height=300,
                       paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
    st.plotly_chart(fig1, use_container_width=True, config={'displayModeBar': False})

    st.subheader("â° å°æ—¶è¡Œä¸ºè¶‹åŠ¿")
    fig2 = px.bar(data['hourly_df'], x='hour', y='cnt', color_discrete_sequence=['#60a5fa'])
    fig2.update_layout(margin=dict(t=30, b=0, l=0, r=0), height=250, xaxis_title="å°æ—¶", yaxis_title="è¡Œä¸ºæ¬¡æ•°",
                       paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
    st.plotly_chart(fig2, use_container_width=True, config={'displayModeBar': False})

    st.subheader("ğŸ”½ ç”¨æˆ·è½¬åŒ–æ¼æ–—")
    fig3 = px.funnel(data['funnel_df'], x='users', y='stage',
                     color_discrete_sequence=['#38bdf8', '#60a5fa', '#a78bfa'])
    fig3.update_layout(margin=dict(t=30, b=0, l=0, r=0), height=250,
                       paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
    st.plotly_chart(fig3, use_container_width=True, config={'displayModeBar': False})

with right_col:
    st.subheader("ğŸŒ å…¨çƒç”¨æˆ·åœ°åŸŸåˆ†å¸ƒ")
    if not data['geo_df'].empty:
        if lottie_globe is not None and 'globe_shown' not in st.session_state:
            st_lottie(lottie_globe, height=120, key="globe")
            st.session_state.globe_shown = True

        fig4 = px.choropleth(
            data['geo_df'],
            locations="country",
            locationmode="country names",
            color="user_count",
            hover_name="country",
            color_continuous_scale="Blues",
            title=""
        )
        fig4.update_layout(
            margin={"r":0,"t":0,"l":0,"b":0},
            height=350,
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)'
        )
        st.plotly_chart(fig4, use_container_width=True, config={'displayModeBar': False})
    else:
        st.info("âš ï¸ æš‚æ— æœ‰æ•ˆçš„åœ°ç†ä½ç½®æ•°æ®")

    st.subheader("ğŸ”¥ çƒ­é—¨å•†å“ï¼ˆTop 5ï¼‰")
    st.dataframe(data['cat_df'], use_container_width=True, hide_index=True)

    st.subheader("ğŸ“¦ æœ€æ–°è®¢å•æ—¥å¿—")
    st.dataframe(data['log_df'][['user_id', 'item_id', 'time']], use_container_width=True, hide_index=True)

# ==================== åº•éƒ¨è¯´æ˜ ====================
st.markdown(
    "<div style='text-align: center; color: #64748b; margin-top: 2rem; font-size: 0.9rem;'>"
    "ğŸ’¡ æ•°æ®æºè‡ª 2014 å¹´åŒ12æ´»åŠ¨ | æ”¯æŒ GeoHash è‡ªåŠ¨å›½å®¶è¯†åˆ« | ç‚«é…·ç§‘æŠ€é£ by Qwen"
    "</div>",
    unsafe_allow_html=True
)
